import streamlit as st
import os
import requests
from bs4 import BeautifulSoup
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import TextLoader, PyPDFLoader, Docx2txtLoader
from langchain.memory import ConversationBufferMemory
from langchain_groq import ChatGroq
import tempfile
from dotenv import load_dotenv
import pymongo
import faiss
import numpy as np

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if "conversation" not in st.session_state:
    st.session_state.conversation = None

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "vector_store" not in st.session_state:
    st.session_state.vector_store = None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞
def load_constitution():
    url = "https://www.akorda.kz/en/constitution-of-the-republic-of-kazakhstan-50912"

    try:
        response = requests.get(url)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')
        main_content = soup.find('div', class_='content-block')

        if main_content:
            content = main_content.get_text(separator=' ', strip=True)
        else:
            content = soup.get_text(separator=' ', strip=True)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".txt") as temp_file:
            temp_file.write(content.encode('utf-8'))
            temp_file_path = temp_file.name

            loader = TextLoader(temp_file_path)
            documents = loader.load()

            os.unlink(temp_file_path)

            return documents

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏: {e}")
        return []

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
def process_uploaded_files(uploaded_files):
    documents = []

    for file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file.name.split('.')[-1]}") as temp_file:
            temp_file.write(file.getvalue())
            temp_file_path = temp_file.name

        if file.name.endswith('.pdf'):
            loader = PyPDFLoader(temp_file_path)
        elif file.name.endswith('.docx'):
            loader = Docx2txtLoader(temp_file_path)
        elif file.name.endswith('.txt'):
            loader = TextLoader(temp_file_path)
        else:
            st.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file.name}")
            os.unlink(temp_file_path)
            continue

        try:
            doc = loader.load()
            documents.extend(doc)
            os.unlink(temp_file_path)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file.name}: {e}")
            os.unlink(temp_file_path)

    return documents

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
def setup_conversation(documents):
    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ —á–∞–Ω–∫–∏
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_documents(documents)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MongoDB
    mongo_conn_string = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
    db_name = "constitution_assistant"
    collection_name = "document_embeddings"

    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç MongoDB
    client = pymongo.MongoClient(mongo_conn_string)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
    if db_name not in client.list_database_names():
        client[db_name].create_collection(collection_name)

    # –°–æ–∑–¥–∞–µ–º FAISS –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    vector_store = FAISS.from_documents(chunks, embeddings)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä –≤ MongoDB
    collection = client[db_name][collection_name]
    for i, chunk in enumerate(chunks):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º embed_documents –≤–º–µ—Å—Ç–æ embed
        vectors = embeddings.embed_documents([chunk.page_content])
        vector = vectors[0]  # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π –≤–µ–∫—Ç–æ—Ä –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫—É—Å–∫–∞
        collection.insert_one({"document": chunk.page_content, "vector": vector})

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è —á–∞—Ç–∞
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á API –¥–ª—è Groq
    groq_api_key = os.getenv("GROQ_API_KEY")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å Groq
    llm = ChatGroq(
        temperature=0,
        groq_api_key=groq_api_key,
        model_name="llama3-70b-8192"  # –í—ã –º–æ–∂–µ—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ –Ω—É–∂–Ω—É—é –º–æ–¥–µ–ª—å
    )

    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
    conversation = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(),
        memory=memory
    )

    return conversation, vector_store

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Streamlit
st.set_page_config(page_title="–ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞", layout="wide")
st.title("–ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω")

with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—é –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞"):
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏..."):
            constitution_documents = load_constitution()
            if constitution_documents:
                st.session_state.conversation, st.session_state.vector_store = setup_conversation(constitution_documents)
                st.success("–ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

    uploaded_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã", accept_multiple_files=True)

    if uploaded_files and st.button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤..."):
            documents = process_uploaded_files(uploaded_files)

            if st.session_state.vector_store is not None:
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                chunks = text_splitter.split_documents(documents)

                st.session_state.vector_store.add_documents(chunks)

                memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
                groq_api_key = os.getenv("GROQ_API_KEY")

                llm = ChatGroq(
                    temperature=0,
                    groq_api_key=groq_api_key,
                    model_name="llama3-70b-8192"
                )

                st.session_state.conversation = ConversationalRetrievalChain.from_llm(
                    llm=llm,
                    retriever=st.session_state.vector_store.as_retriever(),
                    memory=memory
                )
            else:
                st.session_state.conversation, st.session_state.vector_store = setup_conversation(documents)

            st.success(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤!")

# –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ - —á–∞—Ç
st.header("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞")

chat_container = st.container()
with chat_container:
    for i, message in enumerate(st.session_state.chat_history):
        if i % 2 == 0:
            st.write(f"üôã‚Äç‚ôÇÔ∏è **–í—ã:** {message}")
        else:
            st.write(f"ü§ñ **–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:** {message}")

user_question = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:")

if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å") and user_question:
    if st.session_state.conversation is None:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—é –∏–ª–∏ –¥—Ä—É–≥–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã!")
    else:
        with st.spinner("–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞..."):
            st.session_state.chat_history.append(user_question)

            response = st.session_state.conversation({"question": user_question})
            answer = response["answer"]

            st.session_state.chat_history.append(answer)

            st.rerun()  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤

st.markdown("---")
st.markdown("### –û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏")
st.markdown("""  
–≠—Ç–æ—Ç –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–µ–π –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω.  
–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏, –∞ —Ç–∞–∫–∂–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.  

–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:  
- –ú–æ–¥–µ–ª—å LLaMa3 —á–µ—Ä–µ–∑ API Groq  
- –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ FAISS –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞  
- –ê–ª–≥–æ—Ä–∏—Ç–º embeddings –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
""")
